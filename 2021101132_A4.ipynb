{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "714e92f4",
   "metadata": {},
   "source": [
    "# Ensemble Model for Age Prediction\n",
    "\n",
    "The provided Python code is an example of an **ensemble model** for age prediction from facial images. The idea behind an ensemble model is to combine the predictions of several base models to improve the robustness and performance of the prediction.\n",
    "\n",
    "## Base Models\n",
    "\n",
    "In this case, the base models are:\n",
    "\n",
    "1. **ResNetModel**: This is likely a model based on the ResNet (Residual Network) architecture, which is a popular choice for image classification tasks due to its ability to train deep networks.\n",
    "\n",
    "2. **InceptionModel**: This is likely a model based on the Inception architecture (also known as GoogLeNet), another popular choice for image classification tasks, known for its efficient use of model parameters.\n",
    "\n",
    "3. **CNNModel**: This is a generic Convolutional Neural Network model. CNNs are widely used in image classification tasks due to their ability to capture spatial information.\n",
    "\n",
    "## Ensemble Model\n",
    "\n",
    "The `EnsembleModel` class is defined as a subclass of the `nn.Module` class, which is the base class for all neural network modules in PyTorch. The ensemble model takes a list of base models as input and stores them in an `nn.ModuleList`. This is necessary because PyTorch only optimizes the parameters of models that are instances of `nn.Module`.\n",
    "\n",
    "In the `forward` method, the ensemble model computes the output of each base model and averages them. This is known as **model averaging**, a simple yet effective ensemble method. The assumption here is that each base model is equally reliable. If this is not the case, you might want to assign different weights to the outputs of different models.\n",
    "\n",
    "Finally, an instance of the ensemble model is created with instances of the base models, and used for prediction on an input image.\n",
    "\n",
    "Please note that the actual implementations of `ResNetModel`, `InceptionModel`, and `CNNModel` are not provided in the code. You would need to replace these with actual model classes for this code to run.\n",
    "\n",
    "```python\n",
    "# Create instances of your models\n",
    "resnet_model = ResNetModel()\n",
    "inception_model = InceptionModel()\n",
    "cnn_model = CNNModel()\n",
    "\n",
    "# Create an ensemble of the models\n",
    "ensemble_model = EnsembleModel([resnet_model, inception_model, cnn_model])\n",
    "\n",
    "# Use the ensemble model for prediction\n",
    "input_image = # Load your input image\n",
    "output = ensemble_model(input_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cb2486d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T14:29:53.667240Z",
     "iopub.status.busy": "2024-04-21T14:29:53.666912Z",
     "iopub.status.idle": "2024-04-21T14:30:00.519332Z",
     "shell.execute_reply": "2024-04-21T14:30:00.518353Z"
    },
    "papermill": {
     "duration": 6.859416,
     "end_time": "2024-04-21T14:30:00.521794",
     "exception": false,
     "start_time": "2024-04-21T14:29:53.662378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from os.path import join\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1fe9f9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T14:30:00.528806Z",
     "iopub.status.busy": "2024-04-21T14:30:00.528378Z",
     "iopub.status.idle": "2024-04-21T14:30:00.576801Z",
     "shell.execute_reply": "2024-04-21T14:30:00.575992Z"
    },
    "papermill": {
     "duration": 0.054037,
     "end_time": "2024-04-21T14:30:00.578800",
     "exception": false,
     "start_time": "2024-04-21T14:30:00.524763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load datasets\n",
    "class AgeDataset(Dataset):\n",
    "    def __init__(self, data_path, annot_path, train=True):\n",
    "        super(AgeDataset, self).__init__()\n",
    "        self.annot_path = annot_path\n",
    "        self.data_path = data_path\n",
    "        self.train = train\n",
    "        self.ann = pd.read_csv(annot_path)\n",
    "        self.files = self.ann['file_id']\n",
    "        if train:\n",
    "            self.ages = self.ann['age']\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((299, 299)),  # Resize input images to 299x299\n",
    "            transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "            transforms.RandomRotation(10),  # Randomly rotate the image by up to 10 degrees\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_name = self.files[index]\n",
    "        img = Image.open(join(self.data_path, file_name))\n",
    "        img = self.transform(img)\n",
    "        if self.train:\n",
    "            age = self.ages[index]\n",
    "            return img, age\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "train_path = '/kaggle/input/smai-24-age-prediction/content/faces_dataset/train'\n",
    "train_ann = '/kaggle/input/smai-24-age-prediction/content/faces_dataset/train.csv'\n",
    "train_dataset = AgeDataset(train_path, train_ann, train=True)\n",
    "\n",
    "test_path = '/kaggle/input/smai-24-age-prediction/content/faces_dataset/test'\n",
    "test_ann = '/kaggle/input/smai-24-age-prediction/content/faces_dataset/submission.csv'\n",
    "test_dataset = AgeDataset(test_path, test_ann, train=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a7d3bf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T14:30:00.585449Z",
     "iopub.status.busy": "2024-04-21T14:30:00.585153Z",
     "iopub.status.idle": "2024-04-21T14:30:00.594652Z",
     "shell.execute_reply": "2024-04-21T14:30:00.593920Z"
    },
    "papermill": {
     "duration": 0.014951,
     "end_time": "2024-04-21T14:30:00.596597",
     "exception": false,
     "start_time": "2024-04-21T14:30:00.581646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model_with_scheduler(model, train_loader, optimizer, criterion, scheduler, device, num_epochs=15):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            aux_logits, outputs = model(images)\n",
    "            loss1 = criterion(outputs, labels.float().view(-1, 1))\n",
    "            loss2 = criterion(aux_logits, labels.float().view(-1, 1))\n",
    "            loss = loss1 + 0.4 * loss2  # Scale the auxiliary loss by 0.4 as done in the paper\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "        scheduler.step(epoch_loss)  # Adjust learning rate based on epoch loss\n",
    "\n",
    "\n",
    "def predict(loader, model, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for images in tqdm(loader):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            predictions.extend(outputs.flatten().cpu().tolist())\n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f531b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ResNet-based model architecture\n",
    "class ResNetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetModel, self).__init__()\n",
    "        # Load pre-trained ResNet model\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        # Replace the final fully connected layer to adapt to your regression task\n",
    "        num_ftrs = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f42a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model architecture\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 14 * 14, 512)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = x.view(-1, 128 * 14 * 14)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6d46b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InceptionModel, self).__init__()\n",
    "        self.inception = models.inception_v3(pretrained=True)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = self.inception.AuxLogits.fc.in_features\n",
    "        self.inception.AuxLogits.fc = nn.Linear(num_ftrs, 1)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = self.inception.fc.in_features\n",
    "        self.inception.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            # In training mode, we return both outputs\n",
    "            aux_logits, fc = self.inception(x)\n",
    "            return aux_logits, fc\n",
    "        else:\n",
    "            # In evaluation mode, we only return the final output\n",
    "            x = self.inception(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abe9b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, models):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        self.models = nn.ModuleList(models)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outputs = torch.zeros(x.size(0), 1)\n",
    "        for model in self.models:\n",
    "            outputs += model(x)\n",
    "        return outputs / len(self.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52572477",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T14:30:00.602643Z",
     "iopub.status.busy": "2024-04-21T14:30:00.602373Z",
     "iopub.status.idle": "2024-04-21T15:41:17.847607Z",
     "shell.execute_reply": "2024-04-21T15:41:17.846611Z"
    },
    "papermill": {
     "duration": 4277.25489,
     "end_time": "2024-04-21T15:41:17.854009",
     "exception": false,
     "start_time": "2024-04-21T14:30:00.599119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Check if GPU is available, else use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create instances of your models\n",
    "resnet_model = ResNetModel()\n",
    "inception_model = InceptionModel()\n",
    "cnn_model = CNNModel()\n",
    "\n",
    "# Create an ensemble of the models\n",
    "ensemble_model = EnsembleModel([resnet_model, inception_model, cnn_model])\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(ensemble_model.parameters(), lr=0.0001)  # Adjust learning rate if needed\n",
    "\n",
    "# Learning rate scheduler (remain unchanged)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, threshold=1e-3, verbose=True)\n",
    "\n",
    "# Train the model with learning rate scheduling\n",
    "train_model_with_scheduler(ensemble_model, train_loader, optimizer, criterion, scheduler, device,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcc5525c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T15:41:17.864641Z",
     "iopub.status.busy": "2024-04-21T15:41:17.864294Z",
     "iopub.status.idle": "2024-04-21T15:41:36.887441Z",
     "shell.execute_reply": "2024-04-21T15:41:36.886274Z"
    },
    "papermill": {
     "duration": 19.030926,
     "end_time": "2024-04-21T15:41:36.889627",
     "exception": false,
     "start_time": "2024-04-21T15:41:17.858701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:18<00:00,  3.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = predict(test_loader, ensemble_model, device)\n",
    "\n",
    "# Create submission file\n",
    "submission_df = pd.read_csv(test_ann)\n",
    "submission_df['age'] = predictions\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e529a18",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8130765,
     "sourceId": 74586,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30684,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4307.571925,
   "end_time": "2024-04-21T15:41:38.550851",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-21T14:29:50.978926",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
